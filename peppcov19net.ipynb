{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "peppcov19net.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN+/Bq4CvblKILQl+Cyvlcv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tripletk/Pepp-Cov19-Net/blob/main/peppcov19net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vW3Ws645938i"
      },
      "source": [
        "Detecting COVID-19 with Chest X Ray using PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8v0CVwuG9-Jo"
      },
      "source": [
        "Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIfEPk0V9gNn",
        "outputId": "c484be82-41a9-4be2-a2b5-bddfba0bce87"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "print('Using PyTorch version', torch.__version__)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using PyTorch version 1.8.1+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKB-YEMt-nl9"
      },
      "source": [
        "Preapring Training and Test Sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQp1HYxa-piX"
      },
      "source": [
        "class_names = ['normal', 'viral', 'covid']\n",
        "root_dir = 'COVID-19 Radiography Database'\n",
        "source_dirs = ['NORMAL', 'Viral Pneumonia', 'COVID-19']\n",
        "\n",
        "if os.path.isdir(os.path.join(root_dir, source_dirs[1])):\n",
        "    os.mkdir(os.path.join(root_dir, 'test'))\n",
        "\n",
        "    for i, d in enumerate(source_dirs):\n",
        "        os.rename(os.path.join(root_dir, d), os.path.join(root_dir, class_names[i]))\n",
        "\n",
        "    for c in class_names:\n",
        "        os.mkdir(os.path.join(root_dir, 'test', c))\n",
        "\n",
        "    for c in class_names:\n",
        "        images = [x for x in os.listdir(os.path.join(root_dir, c)) if x.lower().endswith('png')]\n",
        "        selected_images = random.sample(images, 30)\n",
        "        for image in selected_images:\n",
        "            source_path = os.path.join(root_dir, c, image)\n",
        "            target_path = os.path.join(root_dir, 'test', c, image)\n",
        "            shutil.move(source_path, target_path)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQY1k4Fb_rE6"
      },
      "source": [
        "Creating Custom Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZu4--tL_snm"
      },
      "source": [
        "class ChestXRayDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, image_dirs, transform):\n",
        "        def get_images(class_name):\n",
        "            images = [x for x in os.listdir(image_dirs[class_name]) if x.lower().endswith('png')]\n",
        "            print(f'Found {len(images)} {class_name} examples')\n",
        "            return images\n",
        "        \n",
        "        self.images = {}\n",
        "        self.class_names = ['normal', 'viral', 'covid']\n",
        "        \n",
        "        for class_name in self.class_names:\n",
        "            self.images[class_name] = get_images(class_name)\n",
        "            \n",
        "        self.image_dirs = image_dirs\n",
        "        self.transform = transform\n",
        "        \n",
        "    \n",
        "    def __len__(self):\n",
        "        return sum([len(self.images[class_name]) for class_name in self.class_names])\n",
        "    \n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        class_name = random.choice(self.class_names)\n",
        "        index = index % len(self.images[class_name])\n",
        "        image_name = self.images[class_name][index]\n",
        "        image_path = os.path.join(self.image_dirs[class_name], image_name) # avoid out of bounds index values of different classes\n",
        "        image = Image.open(image_path).convert('RGB') # Using ResNet18 so have to convert image to RGB\n",
        "        return self.transform(image), self.class_names.index(class_name) # transform for tensor\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3ZuO9VPGPNT"
      },
      "source": [
        "Image Transformations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8Js4hfLGQ5z"
      },
      "source": [
        "train_transform = torchvision.transforms.Compose([\n",
        "  torchvision.transforms.Resize(size=(224, 224)), # convert image to size ResNet expects\n",
        "  torchvision.transforms.RandomHorizontalFlip(), # Used to augment data\n",
        "  torchvision.transforms.ToTensor(),\n",
        "  torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.0406],\n",
        "                                   std=[0.229, 0.224, 0.225]) #Normalize for ResNet18\n",
        "])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9YPKAC9SvEc"
      },
      "source": [
        "test_transform = torchvision.transforms.Compose([\n",
        "  torchvision.transforms.Resize(size=(224, 224)), # convert image to size ResNet expects\n",
        "  torchvision.transforms.ToTensor(),\n",
        "  torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.0406],\n",
        "                                   std=[0.229, 0.224, 0.225]) #Normalize for ResNet18\n",
        "])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCJb4jlnS6oa"
      },
      "source": [
        "Prepare DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "kESCDBSNS8V3",
        "outputId": "1249eec2-8f63-4bb3-c901-bae081e914c5"
      },
      "source": [
        "train_dirs = {\n",
        "    'normal': 'COVID-19 Radiography Database/normal',\n",
        "    'viral': 'COVID-19 Radiography Database/viral',\n",
        "    'covid': 'COVID-19 Radiography Database/covid'\n",
        "}\n",
        "\n",
        "train_dataset = ChestXRayDataset(train_dirs, train_transform)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-936b616d0350>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m }\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChestXRayDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dirs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-a4ecd0b825dd>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, image_dirs, transform)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mclass_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_dirs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_dirs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-a4ecd0b825dd>\u001b[0m in \u001b[0;36mget_images\u001b[0;34m(class_name)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_dirs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dirs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Found {len(images)} {class_name} examples'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'COVID-19 Radiography Database/normal'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jh_WwP8PTGLk"
      },
      "source": [
        "test_dirs = {\n",
        "    'normal': 'COVID-19 Radiography Database/test/normal',\n",
        "    'viral': 'COVID-19 Radiography Database/test/viral',\n",
        "    'covid': 'COVID-19 Radiography Database/test/covid'\n",
        "}\n",
        "\n",
        "test_dataset"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}